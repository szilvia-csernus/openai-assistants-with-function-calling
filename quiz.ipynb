{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e76e39b-8eb1-4345-b0f1-51a400767f8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af035e7a-6594-4a7e-8929-24effdbbf45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 657,
   "id": "b9c44b32-8d19-4d9a-bb55-22f490dd917e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def  geography_question(question, answers):\n",
    "    print(\"\\nChoose the correct answer!\\n\")\n",
    "    print(question)\n",
    "    print('\\n')\n",
    "    for num, ans in enumerate(answers):\n",
    "        print(f\"Option {num+1}.): {ans}\")\n",
    "\n",
    "    print(\"\\n\")\n",
    "    choice = input(\"Your choice: \")\n",
    "    print(answers[int(choice) - 1])\n",
    "          \n",
    "    return answers[int(choice) - 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 747,
   "id": "b22d1fd0-004c-4f61-8baf-30548fd85165",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Choose the correct answer!\n",
      "\n",
      "What is the capital of Hungary?\n",
      "\n",
      "\n",
      "Option 1.): Vilnius\n",
      "Option 2.): Bishkek\n",
      "Option 3.): Budapest\n",
      "Option 4.): Taskent\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Your choice:  3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Budapest\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Budapest'"
      ]
     },
     "execution_count": 747,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geography_question(\"What is the capital of Hungary?\",\n",
    "    [\"Vilnius\", \"Bishkek\", \"Budapest\", \"Taskent\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 679,
   "id": "6c7f0617-da04-4c4b-aaaa-2bc245e75a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "function_json = {'type': 'function',\n",
    "                 'function':{\n",
    "                     'name':'geography_question',\n",
    "                     'description': 'Prints out a Geography question and the possible answers to choose from. Asks the user to input an answer and returns the given answer.\n",
    "                     'parameters':{\n",
    "                         'type':'object',\n",
    "                         'properties':{\n",
    "                             'question':{'type':'string',\n",
    "                                         'description': 'A Geography-related test question'\n",
    "                                        },\n",
    "                            'answers':{'type': 'array',\n",
    "                                       'items': {'type': 'string'},\n",
    "                                       'description': '4 answers to choose from, with only one correct. Include purely the answer strings and dont include any list markings.'\n",
    "                                        }\n",
    "                         },\n",
    "                         'required': ['question','answers']\n",
    "                     }\n",
    "                 }\n",
    "                }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 680,
   "id": "c4ca3c49-d799-41f3-a231-187ed5180551",
   "metadata": {},
   "outputs": [],
   "source": [
    "instructions = \"\"\"You help create a Geography quiz, providing a question and 4 possible answers for the user to \n",
    "                choose from, with only one of them correct. The user responds with an answer, you evaluate if \n",
    "                the user's response is correct.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 681,
   "id": "372fd642-d37f-4136-9937-0395b0773050",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the assistant\n",
    "assistant = client.beta.assistants.create(\n",
    "    name=\"Geography Quiz\",\n",
    "    instructions=instructions,\n",
    "    tools = [function_json],\n",
    "    model = 'gpt-3.5-turbo'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 714,
   "id": "063f4a89-baa8-45b3-8604-dedfb3e2061e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ThreadDeleted(id='thread_FKscHo2C4s1J27T3ejdeUEMe', deleted=True, object='thread.deleted')"
      ]
     },
     "execution_count": 714,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.beta.threads.delete(thread.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 715,
   "id": "f0dd7a99-ff63-4a30-9b20-b4bf9e72b274",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a thread\n",
    "thread = client.beta.threads.create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 716,
   "id": "f5a27d53-fdb4-4dc0-8046-9b82642c9dcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'thread_93cCjExfuosnTvYGpMBiBpPO'"
      ]
     },
     "execution_count": 716,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thread.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 717,
   "id": "fafc63e3-554a-4239-8ea1-605c56849a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create our first message.\n",
    "message = client.beta.threads.messages.create(\n",
    "    thread_id = thread.id,\n",
    "    role = 'user',\n",
    "    content = \"Create a new Geography quiz question. Tell the user if their answer was correct or incorrect, and tell the correct answer if the given answer was incorrect.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 718,
   "id": "d8ac7fce-4902-4b9d-a107-c2f9b4cbf773",
   "metadata": {},
   "outputs": [],
   "source": [
    "run = client.beta.threads.runs.create(\n",
    "        assistant_id = assistant.id,\n",
    "        thread_id = thread.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 719,
   "id": "c0764326-de3c-4310-88ad-aa52c5b5d122",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a run for the thread\n",
    "import time\n",
    "\n",
    "def run_and_wait(run, thread):\n",
    "    while run.status == 'queued' or run.status == 'in_progress':\n",
    "        run = client.beta.threads.runs.retrieve(\n",
    "            thread_id = thread.id,\n",
    "            run_id = run.id)\n",
    "        print(run.status)\n",
    "        time.sleep(2)\n",
    "\n",
    "    # requires_action\n",
    "    return run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 720,
   "id": "3db20a3b-1bfc-4d6c-abc3-a39bc4643cfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "requires_action\n"
     ]
    }
   ],
   "source": [
    "run = run_and_wait(run, thread)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 721,
   "id": "b5813df0-0b39-4781-9379-a4082e3cca06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Run(id='run_NU5VZinJg8HSeNTAmvAVmv5B', assistant_id='asst_QKNrc7ZKPZakQP6EV16kSXyA', cancelled_at=None, completed_at=None, created_at=1718527957, expires_at=1718528557, failed_at=None, incomplete_details=None, instructions=\"You help create a Geography quiz, providing a question and 4 possible answers for the user to \\n                choose from, with only one of them correct. The user responds with an answer, you evaluate if \\n                the user's response is correct.\", last_error=None, max_completion_tokens=None, max_prompt_tokens=None, metadata={}, model='gpt-3.5-turbo', object='thread.run', parallel_tool_calls=True, required_action=RequiredAction(submit_tool_outputs=RequiredActionSubmitToolOutputs(tool_calls=[RequiredActionFunctionToolCall(id='call_sFVtJ23FGaECcUlX1oDfg1eJ', function=Function(arguments='{\"question\":\"Which is the largest desert in the world by area?\",\"answers\":[\"Sahara Desert\",\"Arabian Desert\",\"Gobi Desert\",\"Kalahari Desert\"]}', name='geography_question'), type='function')]), type='submit_tool_outputs'), response_format='auto', started_at=1718527957, status='requires_action', thread_id='thread_93cCjExfuosnTvYGpMBiBpPO', tool_choice='auto', tools=[FunctionTool(function=FunctionDefinition(name='geography_question', description=None, parameters={'type': 'object', 'properties': {'question': {'type': 'string', 'description': 'A Geography-related test question'}, 'answers': {'type': 'array', 'items': {'type': 'string'}, 'description': '4 answers to choose from, with only one correct. Include purely the answer strings and dont include any list markings.'}}, 'required': ['question', 'answers']}), type='function')], truncation_strategy=TruncationStrategy(type='auto', last_messages=None), usage=None, temperature=1.0, top_p=1.0, tool_resources={})"
      ]
     },
     "execution_count": 721,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 722,
   "id": "0dc17e57-4642-4d41-bf6e-786a03d8c262",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RequiredAction(submit_tool_outputs=RequiredActionSubmitToolOutputs(tool_calls=[RequiredActionFunctionToolCall(id='call_sFVtJ23FGaECcUlX1oDfg1eJ', function=Function(arguments='{\"question\":\"Which is the largest desert in the world by area?\",\"answers\":[\"Sahara Desert\",\"Arabian Desert\",\"Gobi Desert\",\"Kalahari Desert\"]}', name='geography_question'), type='function')]), type='submit_tool_outputs')"
      ]
     },
     "execution_count": 722,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run.required_action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 723,
   "id": "55060447-15e3-40ef-b5ae-b6a8d0d7d416",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RequiredActionSubmitToolOutputs(tool_calls=[RequiredActionFunctionToolCall(id='call_sFVtJ23FGaECcUlX1oDfg1eJ', function=Function(arguments='{\"question\":\"Which is the largest desert in the world by area?\",\"answers\":[\"Sahara Desert\",\"Arabian Desert\",\"Gobi Desert\",\"Kalahari Desert\"]}', name='geography_question'), type='function')])"
      ]
     },
     "execution_count": 723,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run.required_action.submit_tool_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 724,
   "id": "ce17abbf-7d70-466d-abba-c0db79545840",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_call = run.required_action.submit_tool_outputs.tool_calls[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 725,
   "id": "b036e3d6-f713-4f4f-b30f-1342e1be83a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "arguments = json.loads(tool_call.function.arguments)\n",
    "function_name = tool_call.function.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 726,
   "id": "bf130d98-25a2-43d7-ab63-4489e74ccc61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'Which is the largest desert in the world by area?',\n",
       " 'answers': ['Sahara Desert',\n",
       "  'Arabian Desert',\n",
       "  'Gobi Desert',\n",
       "  'Kalahari Desert']}"
      ]
     },
     "execution_count": 726,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 727,
   "id": "0b4dce79-2a85-4b02-b901-75d7acd525ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'geography_question'"
      ]
     },
     "execution_count": 727,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 728,
   "id": "ad002542-af00-4095-ae6c-fdbb7d92ed45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Choose the correct answer!\n",
      "\n",
      "Which is the largest desert in the world by area?\n",
      "\n",
      "\n",
      "Option 1: Sahara Desert\n",
      "Option 2: Arabian Desert\n",
      "Option 3: Gobi Desert\n",
      "Option 4: Kalahari Desert\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Your choice:  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sahara Desert\n"
     ]
    }
   ],
   "source": [
    "# We run the required action\n",
    "response = python_question(arguments['question'], arguments['answers'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 729,
   "id": "796229ec-b209-4b70-ac08-ace4f4b2dac9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sahara Desert'"
      ]
     },
     "execution_count": 729,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 730,
   "id": "a511dc28-c116-48fe-ab05-7966d7a137f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We submit the output via submit_tool_output to be used by the assistant, who still has to decide if the given\n",
    "# answer was correct.\n",
    "run = client.beta.threads.runs.submit_tool_outputs(\n",
    "    thread_id = thread.id,\n",
    "    run_id = run.id,\n",
    "    tool_outputs = [{'tool_call_id': tool_call.id,\n",
    "                     'output': json.dumps(response)\n",
    "                    }]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 731,
   "id": "28039213-31a6-4414-9433-4d339ec7dcf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed\n"
     ]
    }
   ],
   "source": [
    "run = run_and_wait(run, thread)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 732,
   "id": "4d5014e5-e0c8-4c6f-9082-cd0818c53123",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = client.beta.threads.messages.list(\n",
    "    thread_id = thread.id,\n",
    "    order = 'asc'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 733,
   "id": "3f7d233f-9a6d-4f78-abd9-7c719dd1d5ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create a new Geography quiz question. Tell the user if their answer was correct or incorrect, and tell the correct answer if the given answer was incorrect.\n",
      "\n",
      "\n",
      "The user's answer \"Sahara Desert\" is correct! The Sahara Desert is indeed the largest desert in the world by area. Great job!\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for message in messages:\n",
    "    print(message.content[0].text.value)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 734,
   "id": "655bd382-ba8d-4bd9-8cc6-d88712cdb192",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To continue with the same thread, we create a new message and repeat all the steps from that point.\n",
    "# I didn't put this functionality into a loop here to better understand how the function calling works.\n",
    "\n",
    "message = client.beta.threads.messages.create(\n",
    "    thread_id = thread.id,\n",
    "    role = 'user',\n",
    "    content = \"Create a new Geography quiz question. Tell the user if their answer was correct or incorrect, and tell the correct answer if the given answer was incorrect.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 735,
   "id": "fa0cf805-c2a7-4492-92b7-f497de5b2faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "run = client.beta.threads.runs.create(\n",
    "        assistant_id = assistant.id,\n",
    "        thread_id = thread.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 736,
   "id": "5b3a4224-21e0-4125-a279-9529f60ad8c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "requires_action\n"
     ]
    }
   ],
   "source": [
    "run = run_and_wait(run, thread)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 737,
   "id": "b4d881fc-ebfd-4470-a548-ae7ddc2cc47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_call = run.required_action.submit_tool_outputs.tool_calls[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 738,
   "id": "1e2c1610-34cf-44aa-8d34-232202a874c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "arguments = json.loads(tool_call.function.arguments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 739,
   "id": "61951c2b-2b67-4e4c-90fc-7460c371f850",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Choose the correct answer!\n",
      "\n",
      "Which country is known as the Land of the Rising Sun?\n",
      "\n",
      "\n",
      "Option 1: Japan\n",
      "Option 2: China\n",
      "Option 3: South Korea\n",
      "Option 4: Thailand\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Your choice:  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Japan\n"
     ]
    }
   ],
   "source": [
    "response = python_question(arguments['question'], arguments['answers'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 740,
   "id": "ad6dc7fd-6126-4f8b-95be-7dd8bbd967e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Japan'"
      ]
     },
     "execution_count": 740,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 741,
   "id": "e77a4c7d-2823-44b7-a2f0-1c9ad793af03",
   "metadata": {},
   "outputs": [],
   "source": [
    "run = client.beta.threads.runs.submit_tool_outputs(\n",
    "    thread_id = thread.id,\n",
    "    run_id = run.id,\n",
    "    tool_outputs = [{'tool_call_id': tool_call.id,\n",
    "                     'output': json.dumps(response)\n",
    "                    }]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 742,
   "id": "f4f60a70-0d82-4a71-9da4-0a762d6e8d82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed\n"
     ]
    }
   ],
   "source": [
    "run = run_and_wait(run, thread)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 743,
   "id": "9c1964ab-bf84-4ee9-8e78-ef5b78352759",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = client.beta.threads.messages.list(\n",
    "    thread_id = thread.id,\n",
    "    order = 'asc'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 744,
   "id": "44f4f9e0-73b7-49a9-91ad-97e8ace51daf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create a new Geography quiz question. Tell the user if their answer was correct or incorrect, and tell the correct answer if the given answer was incorrect.\n",
      "\n",
      "\n",
      "The user's answer \"Sahara Desert\" is correct! The Sahara Desert is indeed the largest desert in the world by area. Great job!\n",
      "\n",
      "\n",
      "Create a new Geography quiz question. Tell the user if their answer was correct or incorrect, and tell the correct answer if the given answer was incorrect.\n",
      "\n",
      "\n",
      "The user's answer \"Japan\" is correct! Japan is indeed known as the Land of the Rising Sun. Well done!\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for message in messages:\n",
    "    print(message.content[0].text.value)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 745,
   "id": "994de96d-086a-48e7-abe1-11b1c771c5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For debugging:\n",
    "run_steps = client.beta.threads.runs.steps.list(\n",
    "    thread_id = thread.id,\n",
    "    run_id = run.id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 746,
   "id": "d883d2ba-f65e-498c-be9a-ac3871c032e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MessageCreationStepDetails(message_creation=MessageCreation(message_id='msg_jPvuZBEqDPMGDXL2sFV7z8BP'), type='message_creation')\n",
      "\n",
      "\n",
      "ToolCallsStepDetails(tool_calls=[FunctionToolCall(id='call_6g9YpWRucBoHZiWkHRb1GmjC', function=Function(arguments='{\"question\":\"Which country is known as the Land of the Rising Sun?\",\"answers\":[\"Japan\",\"China\",\"South Korea\",\"Thailand\"]}', name='geography_question', output='\"Japan\"'), type='function')], type='tool_calls')\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for step in run_steps:\n",
    "    print(step.step_details)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 678,
   "id": "1cf56606-1ce7-4dd2-9252-c3ec214cdcab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AssistantDeleted(id='asst_tD95RPQx1hNl1pChSjAl8Z19', deleted=True, object='assistant.deleted')"
      ]
     },
     "execution_count": 678,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Delete the assistant:\n",
    "client.beta.assistants.delete(assistant.id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
